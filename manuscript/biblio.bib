@book{Goos2011,
author = {Goos, Peter and Jones, Bradley},
doi = {10.1016/0377-2217(95)90051-9},
file = {:home/u0106869/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Goos, Jones - 2011 - Optimal design of experiments. A case study approach.pdf:pdf},
isbn = {9780470744611},
issn = {03772217},
keywords = {data augmentation,sample selection,sample selection manuscript},
mendeley-groups = {Master Thesis,Books},
mendeley-tags = {data augmentation,sample selection,sample selection manuscript},
pages = {305},
publisher = {John Wiley {\&} Sons},
title = {{Optimal design of experiments. A case study approach}},
year = {2011}
}
@article{Shawe-Taylor1993,
abstract = {A proof that a concept class is learnable provided the Vapnik-Chervonenkis dimension is finite is given. The proof is more explicit than previous proofs and introduces two new parameters which allow bounds on the sample size obtained to be improved by a factor of approximately 4 log2(e). {\textcopyright} 1993.},
author = {Shawe-Taylor, John and Anthony, Martin and Biggs, N. L.},
doi = {10.1016/0166-218X(93)90179-R},
file = {:home/u0106869/vfonsecad/kul{\_}phd/literature/1993{\_}Taylor{\_}bound{\_}sample{\_}size.pdf:pdf},
issn = {0166218X},
journal = {Discrete Applied Mathematics},
keywords = {Learning,Probably Approximately Correct (PAC),Vapnik-Chervonenkis dimension,model complexity,sample,sample selection manuscript},
mendeley-tags = {model complexity,sample selection manuscript},
number = {1},
pages = {65--73},
title = {{Bounding sample size with the Vapnik-Chervonenkis dimension}},
volume = {42},
year = {1993}
}
@article{Brandmaier2012,
abstract = {Several applications, such as risk assessment within REACH or drug discovery, require reliable methods for the design of experiments and efficient testing strategies. Keeping the number of experiments as low as possible is important from both a financial and an ethical point of view, as exhaustive testing of compounds requires significant financial resources and animal lives. With a large initial set of compounds, experimental design techniques can be used to select a representative subset for testing. Once measured, these compounds can be used to develop quantitative structure-activity relationship models to predict properties of the remaining compounds. This reduces the required resources and time. D-Optimal design is frequently used to select an optimal set of compounds by analyzing data variance. We developed a new sequential approach to apply a D-Optimal design to latent variables derived from a partial least squares (PLS) model instead of principal components. The stepwise procedure selects a new set of molecules to be measured after each previous measurement cycle. We show that application of the D-Optimal selection generates models with a significantly improved performance on four different data sets with end points relevant for REACH. Compared to those derived from principal components, PLS models derived from the selection on latent variables had a lower root-mean-square error and a higher Q2 and R2. This improvement is statistically significant, especially for the small number of compounds selected.},
author = {Brandmaier, Stefan and Sahlin, Ullrika and Tetko, Igor V. and {\"{O}}berg, Tomas},
doi = {10.1021/ci3000198},
file = {:home/u0106869/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Brandmaier et al. - 2012 - PLS-optimal A stepwise D-Optimal design based on latent variables.pdf:pdf},
issn = {15499596},
journal = {Journal of Chemical Information and Modeling},
keywords = {experimental design,sample selection manuscript},
mendeley-groups = {PhD/Proposal},
mendeley-tags = {experimental design,sample selection manuscript},
number = {4},
pages = {975--983},
pmid = {22462577},
title = {{PLS-optimal: A stepwise D-Optimal design based on latent variables}},
volume = {52},
year = {2012}
}
@article{Aernouts2011,
abstract = {The composition of produced milk has great value for the dairy farmer. It determines the economic value of the milk and provides valuable information about the metabolism of the corresponding cow. Therefore, online measurement of milk components during milking 2 or more times per day would provide knowledge about the current health and nutritional status of each cow individually. This information provides a solid basis for optimizing cow management. The potential of visible and near-infrared (Vis/NIR) spectroscopy for predicting the fat, crude protein, lactose, and urea content of raw milk online during milking was, therefore, investigated in this study. Two measurement modes (reflectance and transmittance) and different wavelength ranges for Vis/NIR spectroscopy were evaluated and their ability to measure the milk composition online was compared. The Vis/NIR reflectance measurements allowed for very accurate monitoring of the fat and crude protein content in raw milk (R(2){\textgreater}0.95), but resulted in poor lactose predictions (R(2){\textless}0.75). In contrast, Vis/NIR transmittance spectra of the milk samples gave accurate fat and crude protein predictions (R(2){\textgreater}0.90) and useful lactose predictions (R(2)=0.88). Neither Vis/NIR reflectance nor transmittance spectroscopy lead to an acceptable prediction of the milk urea content. Transmittance spectroscopy can thus be used to predict the 3 major milk components, but with lower accuracy for fat and crude protein than the reflectance mode. Moreover, the small sample thickness (1mm) required for NIR transmittance measurement considerably complicates its online use.},
author = {Aernouts, B. and Polshin, E. and Lammertyn, J. and Saeys, W.},
doi = {10.3168/jds.2011-4354},
file = {:home/u0106869/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Aernouts et al. - 2011 - Visible and near-infrared spectroscopic analysis of raw milk for cow health monitoring Reflectance or transmitt.pdf:pdf},
isbn = {0022-0302},
issn = {00220302},
journal = {Journal of Dairy Science},
keywords = {2011,accepted july 23,dairy management,health monitoring,milk,preprocessing,received march 10,sample selection manuscript,variable selection,visible and near-infrared spectroscopy},
mendeley-groups = {PhD/CaseStudies{\_}Applications},
mendeley-tags = {milk,preprocessing,variable selection,sample selection manuscript},
number = {11},
pages = {5315--5329},
pmid = {22032354},
publisher = {Elsevier},
title = {{Visible and near-infrared spectroscopic analysis of raw milk for cow health monitoring: Reflectance or transmittance?}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0022030211005583},
volume = {94},
year = {2011}
}
@article{Bobelyn2010,
abstract = {The effect of cultivar, season, shelf-life and origin on the accuracy of near infrared (NIR) calibration models for the soluble solids content (SSC) and firmness of apple was studied based on a large spectral data set based on approximately 6000 apple fruit from different cultivars, origins, shelf-life exposure time and seasons. To interpret the variance in the spectra with respect to biological variability, functional analysis of variance (FANOVA) was used. From the FANOVA analysis it was concluded that the effects of cultivar, origin and shelf-life exposure time on the NIR spectra were all significant. The largest differences in the spectra were found around the water absorption peaks (970, 1170 and 1450 nm). External validations using independent data sets showed that the accuracy of the models increased considerably when more variability was included in the calibration data set. In general the RMSEP for predictions of the SSC were in the range 0.6-0.8 Â°Brix, while for Magness Taylor firmness it was 5.9-8.8 N, depending on the cultivar. It was shown that atypical data can lead to large validation errors. It is, therefore, important to collect a calibration data set which is sufficiently representative for future samples to be analyzed with the developed calibration models and to develop simple procedures for model adaptation during practical use. {\textcopyright} 2009 Elsevier B.V. All rights reserved.},
author = {Bobelyn, Els and Serban, Anca Sabina and Nicu, Mihai and Lammertyn, Jeroen and Nicolai, Bart M. and Saeys, Wouter},
doi = {10.1016/j.postharvbio.2009.09.006},
file = {:home/u0106869/vfonsecad/kul{\_}phd/literature/2010{\_}bobelyn.pdf:pdf},
issn = {09255214},
journal = {Postharvest Biology and Technology},
keywords = {Apple,FANOVA,Firmness,Fruit,Functional data analysis,NIR,Nondestructive,Quality,Robustness,SSC,Spectroscopy,sample selection manuscript},
mendeley-tags = {sample selection manuscript},
number = {3},
pages = {133--143},
title = {{Postharvest quality of apple predicted by NIR-spectroscopy: Study of the effect of biological variability on spectra and model performance}},
volume = {55},
year = {2010}
}
@article{Saeys2005,
abstract = {In this research, the feasibility of a mobile spectroscopy instrument (Zeiss Corona 45 visnir fibre remote) in the visible (VIS) and near infrared (NIR) wavebands for onsite and online analysis of pig manure was investigated. The sensor was calibrated using the one-out cross-validation technique on a set of pig manure samples collected in the spring of 2004 and validated for its 'true' prediction accuracy on a set of samples collected in the spring of 2003 from different Flemish farms. Based on the values of coefficient of determination r2 and the ratio of standard deviation of validation set to root mean square error of cross-validation, the prediction results were evaluated as excellent for dry matter content, good for organic matter content and total nitrogen and approximate for ammonium nitrogen, phosphorus and magnesium. The calibrations for potassium and calcium were only able to discriminate between high and low values. These are encouraging results to recommend the VIS-NIR spectroscopy instrument for onsite measurement of manure composition. This sensor could promote a better manure management based on onsite or even online analysis during haul-out or soil application stages. {\textcopyright} 2005 Silsoe Research Institute. All rights reserved.},
author = {Saeys, W. and Mouazen, A. M. and Ramon, H.},
doi = {10.1016/j.biosystemseng.2005.05.001},
file = {:home/u0106869/Downloads/2005{\_}saeys{\_}pig{\_}manure.pdf:pdf},
issn = {15375110},
journal = {Biosystems Engineering},
keywords = {sample selection manuscript},
mendeley-tags = {sample selection manuscript},
number = {4},
pages = {393--402},
title = {{Potential for onsite and online analysis of pig manure using visible and near infrared reflectance spectroscopy}},
volume = {91},
year = {2005}
}
@book{Diaz-Olivares2020,
abstract = {On-farm monitoring of milk composition can support close control of the udder and metabolic health of individual dairy cows. In previous studies, near-infrared (NIR) spectroscopy applied to milk analysis has proven useful for predicting the main components of raw milk (fat, protein, and lactose). In this contribution, we present and evaluate a precise tool for online milk composition analysis on the farm. For each milking, the online analyzer automatically collects and analyses a representative milk sample. The system acquires the NIR transmission spectra of the milk samples in the wavelength range from 960 to 1690 nm and performs a milk composition prediction afterward. Over a testing period of 8 weeks, the sensor collected 1165 NIR transmittance spectra of raw milk samples originating from 36 cows for which reference values were obtained for fat, protein, and lactose. For the same online sensor system, two calibration scenarios were evaluated: training post-hoc prediction models based on a representative set of calibration samples (n = 319) acquired over the entire testing period, with different cows in the calibration and test set, and training real-time prediction models exclusively on the samples acquired in the first week of the testing period (n = 308). The obtained prediction models were thoroughly tested on all the remaining samples not included in the calibration sets (n respectively 846 and 857). For the post-hoc prediction models, this resulted in an overall prediction error (root-mean-squared error of prediction, RMSEP) smaller than 0.080{\%} (all {\%} are in wt/wt) for milk fat (range 1.5â6.3{\%}), protein (2.6â4.3{\%}) and lactose (4â5.1{\%}), with a coefficient of determination R2 of 0.989, 0.947 and 0.689 for fat, protein, and lactose respectively. For the real-time prediction models, the RMSEP was smaller than 0.092{\%} for milk fat and lactose, and 0.110{\%} for protein, with an R2 of 0.989 (fat), 0.894 (protein) and 0.644 (lactose). The milk lactose predictions could be further improved (RMSEP = 0.088{\%}, R2 = 0.675) by taking into account a cow-specific bias. The presented online sensor system using the real-time prediction approach can thus be used for detailed and autonomous on-farm monitoring of milk composition after each individual milking, as its accuracy is well within the requirements by the International Committee for Animal Recording (ICAR) for on-farm milk analyzers and even meet the standards for laboratory analysis systems for fat and lactose. For this real-time prediction approach, a drift was observed in the predictions, especially for protein. Therefore, further research on the development of online calibration maintenance techniques is required to correct for this model drift and further improve the performance of this sensor system.},
author = {Diaz-Olivares, Jose A. and Adriaens, Ines and Stevens, Els and Saeys, Wouter and Aernouts, Ben},
booktitle = {Computers and Electronics in Agriculture},
doi = {10.1016/j.compag.2020.105734},
file = {:home/u0106869/Downloads/2020{\_}diaz{\_}jose.pdf:pdf},
isbn = {7703039020},
issn = {01681699},
keywords = {Health monitoring,Milk,Near-infrared spectroscopy,Real-time prediction,sample selection manuscript},
mendeley-tags = {sample selection manuscript},
title = {{Online milk composition analysis with an on-farm near-infrared sensor}},
volume = {178},
year = {2020}
}
@article{He2015,
abstract = {A calibration set comprises the multidimensional space that represents the samples for prediction. The representative ability of a calibration set is a major factor that affects the predictive performance of a multivariate regression. A new reference value (YR)-based sample-selection algorithm that assembles a dependent value (y-value) uniform distribution is presented to assure the representation. The existing typical sample-selection algorithm is used for comparison. A set of soy sauce data is used as a set of typical samples that have a complex solution. Comparing the prediction results, it is shown that YR sample-selection has similar prediction performance to that of sample set partitioning based on joint x-y distances (SPXY), but with a simpler algorithm. The calibration models of the y-reference-included sample sets (SPXY and YR) are more accurate than those of y-reference-excluded sample sets (RS and KS). After modeling with the selected representative samples, the performances of YR and SPXY are comparable to that of full sample modeling with fewer samples.},
author = {He, Zhonghai and Li, Mengchao and Ma, Zhenhe},
doi = {10.1016/j.chemolab.2015.09.001},
file = {:home/u0106869/vfonsecad/kul{\_}phd/literature/sample{\_}selection/2015{\_}he{\_}sample-selec-application.pdf:pdf},
issn = {18733239},
journal = {Chemometrics and Intelligent Laboratory Systems},
keywords = {Prediction performance,Reference value base,Sample selection,Soy sauce samples,sample selection manuscript},
mendeley-tags = {sample selection manuscript},
pages = {72--76},
publisher = {Elsevier B.V.},
title = {{Design of a reference value-based sample-selection method and evaluation of its prediction capability}},
url = {http://dx.doi.org/10.1016/j.chemolab.2015.09.001},
volume = {148},
year = {2015}
}
@article{Au2020,
abstract = {Near infrared spectroscopy is widely used to rapidly and cost-effectively collect chemical information from plant samples. Large datasets with hundreds to thousands of spectra and reference values are increasingly becoming more common as researchers accumulate data over many years or across research groups. These datasets potentially contain great spectral and chemical variation and could produce a broadly-applicable calibration model. In this study, partial least squares regression was used to model relationships between near infrared spectra and the foliar concentration of two ecologically-important chemical traits, available nitrogen and total formylated phloroglucinol compounds in Eucalyptus leaves. The nested spatial structure within the extensive dataset of spectra and reference values from 80 species of Eucalyptus was taken into account during calibration development and model validation. Geographic variation amongst samples influenced how well available nitrogen could be predicted. Predictive error of the model was greatest when tested against samples from different Australian states and local government areas to the calibration set. In addition, the results showed that simply relying on spectral variation (assessed by Mahalanobis distance) may mislead researchers into how many reference values are needed. The prediction accuracy of the model of available nitrogen differed little whether 300 or up to 987 calibration samples were included, which indicated that an excessive number of reference values were obtained. Lastly, a suitable multi-species calibration for formylated phloroglucinol compounds was produced and the difficulties associated with predicting complex chemical traits were discussed. Directing effort towards broadly applicable models will encourage sharing of calibration models across projects and research groups and facilitate the integration of near infrared spectroscopy in many research fields.},
author = {Au, Jessie and Youngentob, Kara N. and Foley, William J. and Moore, Ben D. and Fearn, Tom},
doi = {10.1177/0967033520902536},
file = {:home/u0106869/vfonsecad/kul{\_}phd/literature/sample{\_}selection/2015{\_}on/2020-Au-Sample-selection-calibration-and-va.pdf:pdf},
issn = {17516552},
journal = {Journal of Near Infrared Spectroscopy},
keywords = {Available nitrogen,forage quality,formylated phloroglucinol compounds,herbivore,large datasets,near infrared,partial least squares regression,sample selection,sample selection manuscript,sample size},
mendeley-tags = {sample selection,sample selection manuscript},
title = {{Sample selection, calibration and validation of models developed from a large dataset of near infrared spectra of tree leaves}},
year = {2020}
}
@misc{Saeys2019,
abstract = {Vibrational spectroscopy methods are widely investigated as fast and non-destructive alternatives for postharvest quality evaluation. As these methods measure spectral responses at a large number of wavebands correlated to the quality traits of interest, multivariate calibration equations have to be built to estimate the quality traits from the acquired spectra. This paper provides an overview of the most important multivariate data analysis techniques for exploring spectral data, detecting outliers and building calibration models for predicting the quality traits of interest. Both linear and non-linear calibration methods are discussed for quantitative (continuous) and qualitative (discrete) quality traits. For each of the presented methods the theory is explained, followed by illustration of an example case from the postharvest domain and a discussion of applications of this technique for postharvest quality evaluation based on spectral sensors. As spectral preprocessing, careful validation and calibration transfer are crucial aspects for successful implementation of spectral sensors for postharvest quality evaluation, special attention is given to these aspects. Finally, conclusions are drawn and recommendations are made with respect to the steps to take and points of attention for successful calibration.},
author = {Saeys, Wouter and {Nguyen Do Trong}, N. and {Van Beers}, R. and Nicola{\"{i}}, Bart M.},
booktitle = {Postharvest Biology and Technology},
doi = {10.1016/j.postharvbio.2019.110981},
file = {:home/u0106869/vfonsecad/kul{\_}phd/literature/Chemometrics Review{\_}2019{\_}Saeys{\_}Accepted version.pdf:pdf},
issn = {09255214},
keywords = {Classification,Multivariate data analysis,Preprocessing,Spectra,Transfer,Validation,sample selection,sample selection manuscript},
mendeley-tags = {sample selection,sample selection manuscript},
title = {{Multivariate calibration of spectroscopic sensors for postharvest quality evaluation: A review}},
volume = {158},
year = {2019}
}
@article{Chapelle2002,
abstract = {Model selection is an important ingredient of many machine learning algorithms, in particular when the sample size in small, in order to strike the right trade-off between overfitting and underfitting. Previous classical results for linear regression are based on an asymptotic analysis. We present a new penalization method for performing model selection for regression that is appropriate even for small samples. Our penalization is based on an accurate estimator of the ratio of the expected training error and the expected generalization error, in terms of the expected eigenvalues of the input covariance matrix.},
author = {Chapelle, Olivier and Vapnik, Vladimir and Bengio, Yoshua},
doi = {10.1023/A:1013943418833},
file = {:home/u0106869/vfonsecad/kul{\_}phd/literature/2002{\_}Vapnik{\_}Chapelle{\_}ModelSelectionForSmallSampleRe.pdf:pdf},
issn = {08856125},
journal = {Machine Learning},
keywords = {Model selection,Parametric regression,Uniform convergence bounds,model complexity,sample selection manuscript},
mendeley-tags = {model complexity,sample selection manuscript},
number = {1-3},
pages = {9--23},
title = {{Model selection for small sample regression}},
volume = {48},
year = {2002}
}
@article{Vapnik2019,
abstract = {Existing mathematical model of learning requires using training data find in a given subset of admissible function the function that minimizes the expected loss. In the paper this setting is called Second selection problem. Mathematical model of learning in this paper along with Second selection problem requires to solve the so-called First selection problem where using training data one first selects from wide set of function in Hilbert space an admissible subset of functions that include the desired function and second selects in this admissible subset a good approximation to the desired function. Existence of two selection problems reflects fundamental property of Hilbert space, existence of two different concepts of convergence of functions: weak convergence (that leads to solution of the First selection problem) and strong convergence (that leads to solution of the Second selection problem). In the paper we describe simultaneous solution of both selection problems for functions that belong to Reproducing Kernel Hilbert space. The solution is obtained in closed form.},
author = {Vapnik, V. N.},
doi = {10.1134/S000511791911002X},
file = {:home/u0106869/vfonsecad/kul{\_}phd/literature/2019{\_}Vapnik{\_}Article{\_}CompleteStatisticalTheoryOfLea.pdf:pdf},
issn = {16083032},
journal = {Automation and Remote Control},
keywords = {first selection problem,model complexity,reproducing kernel Hilbert space,sample selection manuscript,second selection problem,statistical learning theory,training data},
mendeley-tags = {model complexity,sample selection manuscript},
number = {11},
pages = {1949--1975},
title = {{Complete Statistical Theory of Learning}},
volume = {80},
year = {2019}
}
@article{Nawar2018,
abstract = {The selection of samples for modelling of visible and near infrared (vis-NIR) spectra for prediction of soil organic carbon (OC) is a crucial step for improving model prediction performance. This paper aims at comparing three soil sample selection methods coupled with spiking technique for improving on-line prediction performance of OC. Sample selection methods included random selection (RS), Kennard-Stone (KS) algorithm and similarity analysis (SA). Soil vis-NIR spectra was measured with an on-line fibre-type vis-NIR spectrophotometer (tec5 Technology for Spectroscopy, Germany), with a spectral range of 305â2200 nm. A multiple field sample set (268 samples) was merged with samples (148 samples) collected from one target field, and the resulted sample set was subjected to the three sample selection methods. After dividing spectra into calibration and prediction sets, partial least squares regression (PLSR) was run on the calibration set to develop calibration models for OC, and resulted models were validated using samples of the prediction set. Results show that SA performed generally better than its competitors, especially when there were 58 spiked samples used in the calibration set (54{\%} of total spiked samples of 106), with the best residual prediction deviation (RPD) and root mean squares error of prediction (RMSEP) of 2.14â2.54 and 0.16â0.15{\%} for laboratory and on-line prediction. KS and RS performed similarly, but depending on the size of the calibration set, KS produced slightly better models. This indicates that the proposed SA coupled with spiking holds great potential in the optimization of a calibration set size and may serve as a novel and efficient tool for balancing the cost and quality of visâNIR calibrations for estimating OC.},
author = {Nawar, Said and Mouazen, Abdul M.},
doi = {10.1016/j.compag.2018.06.042},
file = {:home/u0106869/vfonsecad/kul{\_}phd/literature/sample{\_}selection/2018{\_}nawar{\_}sample-sel-similarity-analysis.pdf:pdf},
issn = {01681699},
journal = {Computers and Electronics in Agriculture},
keywords = {Partial least squares regression,Sample selection,Soil organic carbon,Spiking,Vis-NIR spectroscopy,sample selection,sample selection manuscript},
mendeley-tags = {sample selection,sample selection manuscript},
number = {May},
pages = {469--477},
publisher = {Elsevier},
title = {{Optimal sample selection for measurement of soil organic carbon using on-line vis-NIR spectroscopy}},
url = {https://doi.org/10.1016/j.compag.2018.06.042},
volume = {151},
year = {2018}
}
@article{Rodionova2008,
abstract = {A new technique for representative subset selection is presented. The advocated method selects unambiguously the most important objects among the calibration set and uses this subset for the model development without significant deterioration in the predictive ability. The method is called boundary subset selection and it is an inherent part of the Simple Interval Calculation (SIC) approach. SIC is a method for linear modeling, which is based on the assumption of error boundedness. The primary SIC consequence is an object status classification (OSClas) that reveals the most influential objects and also designates the most stable and reliable ones. The OSClas is used as the main tool for representative subset selection. The presented results are compared with widely used Kennard-Stone algorithm and D-optimal design procedure employing three real-world examples. Copyright {\textcopyright} 2008 John Wiley {\&} Sons, Ltd.},
author = {Rodionova, Oxana Y. and Pomerantsev, Alexey L.},
doi = {10.1002/cem.1103},
file = {:home/u0106869/vfonsecad/kul{\_}phd/literature/sample{\_}selection/2008{\_}rodionova-sample-sel-subset-strategy.pdf:pdf},
issn = {08869383},
journal = {Journal of Chemometrics},
keywords = {Object status classification,Projection methods,Representative subset selection,SIC method,sample selection,sample selection manuscript},
mendeley-tags = {sample selection,sample selection manuscript},
number = {11-12},
pages = {674--685},
title = {{Subset selection strategy}},
volume = {22},
year = {2008}
}
@article{Kennard1969,
abstract = {A computer oriented method which assists in the construction of response surface type experimental plans is described. It takes into account constraints met in practice that standard procedures do not consider explicitly. The method is a sequential one and each step covers the experimental region uniformly. Applications to well-known situations are given to demonstrate the reasonableness of the procedure. Application to a "messy" design situation is given to demonstrate its novelty},
author = {Kennard, R and Stone, L},
doi = {10.2307/1266219},
file = {:home/u0106869/vfonsecad/kul{\_}phd/literature/sample{\_}selection/1969{\_}ks{\_}cadex.pdf:pdf},
issn = {00401706},
journal = {Technometrics},
keywords = {sample selection,sample selection manuscript},
mendeley-tags = {sample selection,sample selection manuscript},
number = {1},
pages = {13},
title = {{Computer Aided Design of Experiments}},
volume = {11},
year = {1969}
}
@article{Snee1977,
abstract = {Methods to determine the validity of regression models include comparison of model predictions and coefficients with theory, collection of new data to check model predictions. comparison of results with theoretical model calculations, and data splitting or cross-validation in which a portion of the data is used to estimate the model coefficients, and the remainder of the data is used to measure the prediction accuracy of the model. An expository review of these methods is presented. It is concluded that data splitting is an effective method of model validation when it is not practical to collect new data to test the model. The DUPLEX algorithm, developed by R. W. Kennard, is recommended for dividing the data into the estimation set and prediction set when there is no obvious variable such as time to use as a basis to split the data. Several examples are included to illustrate the various methods of model validation. {\textcopyright} 1977 Taylor {\&} Francis Group, LLC.},
author = {Snee, Ronald D.},
doi = {10.1080/00401706.1977.10489581},
file = {:home/u0106869/vfonsecad/kul{\_}phd/literature/sample{\_}selection/1977{\_}snee{\_}duplex{\_}alg.pdf:pdf},
issn = {15372723},
journal = {Technometrics},
keywords = {Cross Validation,Data Splitting,Model Assessment,Model Validation,Regression Analysis,sample selection,sample selection manuscript},
mendeley-tags = {sample selection,sample selection manuscript},
number = {4},
pages = {415--428},
title = {{Validation of Regression Models: Methods and Examples}},
volume = {19},
year = {1977}
}
@article{He2019,
abstract = {Training sample selection is widely accepted as an important step in developing a near-infrared (NIR) spectroscopic model. For industrial applications, the initial training dataset is usually selected empirically. This process is time-consuming, and updating the structure of the modeling dataset online is difficult. Considering the static structure of the modeling dataset, the performance of the established NIR model could be degraded in the online process. To cope with this issue, an active training sample selection and updating strategy is proposed in this work. The advantage of the proposed approach is that it can select suitable modeling samples automatically according to the process information. Moreover, it can adjust model coefficients in a timely manner and avoid arbitrary updating effectively. The effectiveness of the proposed method is validated by applying the method to an industrial gasoline blending process.},
author = {He, Kaixun and Wang, Kai and Yan, Yayun},
doi = {10.1016/j.cjche.2019.02.018},
file = {:home/u0106869/vfonsecad/kul{\_}phd/literature/sample{\_}selection/2019{\_}he{\_}sample{\_}selection{\_}chinese{\_}journal.pdf:pdf},
issn = {10049541},
journal = {Chinese Journal of Chemical Engineering},
keywords = {Chemical processes,Gasoline blending,Near-infrared spectroscopy,Process systems,Soft sensor,sample selection,sample selection manuscript},
mendeley-tags = {sample selection,sample selection manuscript},
number = {11},
pages = {2749--2758},
publisher = {Elsevier B.V.},
title = {{Active training sample selection and updating strategy for near-infrared model with an industrial application}},
url = {https://doi.org/10.1016/j.cjche.2019.02.018},
volume = {27},
year = {2019}
}
@article{Naes1990,
author = {N{\ae}s, T. and Isaksson, T.},
file = {:home/u0106869/vfonsecad/kul{\_}phd/literature/revised-papers/1990{\_}isaksson{\_}sample{\_}selection{\_}spectral{\_}measurements.pdf:pdf},
journal = {Applied Spectroscopy},
keywords = {sample selection,sample selection manuscript},
mendeley-tags = {sample selection,sample selection manuscript},
pages = {1152--1158},
title = {{Selection of samples for calibration in near-infrared spectroscopy. Part II: Selection based on Spectral Measurements}},
volume = {44},
year = {1990}
}
@article{Shetty2012a,
abstract = {The effect of using representative calibration sets with fewer samples was explored and discussed. The data set consisted of near-infrared reflectance (NIR) spectra of grass samples. The grass samples were taken from different years covering a wide range of species and cultivars. Partial least squares regression (PLSR), a chemometric method, has been applied on NIR spectroscopy data for the determination of the nitrogen (N) concentration in these grass samples. The sample selection method based on NIR spectral data proposed by Puchwein and the CADEX (computer aided design of experiments) algorithm were used and compared. Both Puchwein and CADEX methods provide a calibration set equally distributed in space, and both methods require a minimum prior of knowledge. The samples were also selected randomly using complete random, cultivar random (year fixed), year random (cultivar fixed) and interaction (cultivar Ã year fixed) random procedures to see the influence of different factors on sample selection. Puchwein's method performed best with lowest RMSEP followed by CADEX, interaction random, year random, cultivar random and complete random. Out of 118 samples of the complete calibration set, 19 samples were selected as minimal number of representative samples. RMSEP values obtained for subsets selected using Puchwein, CADEX and using full calibration set were 0.099{\%} N, 0.109{\%} N and 0.092{\%} N respectively. The result indicated that the selection of representative calibration samples can effectively enhance the cost-effectiveness of NIR spectral analysis by reducing the number of analyzed samples in the calibration set by more than 80{\%}, which substantially reduces the effort of laboratory analyses with no significant loss in prediction accuracy. {\textcopyright} 2011 Elsevier B.V.},
author = {Shetty, Nisha and Rinnan, {\AA}smund and Gislum, Ren{\'{e}}},
doi = {10.1016/j.chemolab.2011.11.013},
file = {:home/u0106869/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shetty, Rinnan, Gislum - 2012 - Selection of representative calibration sample sets for near-infrared reflectance spectroscopy to pre(2).pdf:pdf},
issn = {01697439},
journal = {Chemometrics and Intelligent Laboratory Systems},
keywords = {CADEX,NIR,Nitrogen,PLSR,Puchwein's method,Representative calibration samples,sample selection,sample selection manuscript},
mendeley-groups = {PhD},
mendeley-tags = {sample selection,sample selection manuscript},
number = {1},
pages = {59--65},
publisher = {Elsevier B.V.},
title = {{Selection of representative calibration sample sets for near-infrared reflectance spectroscopy to predict nitrogen concentration in grasses}},
url = {http://dx.doi.org/10.1016/j.chemolab.2011.11.013},
volume = {111},
year = {2012}
}
@article{Liu2019,
abstract = {In constructing models for predicting soil organic matter (SOM) by using visible and near-infrared (vis-NIR) spectroscopy, the selection of representative calibration samples is decisive. Few researchers have studied the inclusion of spectral pretreatments in the sample selection strategy. We collected 108 soil samples and applied six commonly used spectral pretreatments to preprocess soil spectra, namely, Savitzky-Golay (SG) smoothing, first derivative (FD), logarithmic function log(1/R), mean centering (MC), standard normal variate (SNV), and multiplicative scatter correction (MSC). Then, the Kennard-Stone (KS) strategy was used to select calibration samples based on the pretreated spectra, and the size of the calibration set varied from 10 samples to 86 samples (80{\%} of the total samples). These calibration sets were employed to construct partial least squares regression models (PLSR) to predict SOM, and the built models were validated by a set of 21 samples (20{\%} of the total samples). The results showed that 64-78{\%} of the calibration sets selected by the inclusion of pretreatment demonstrated significantly better performance of SOM estimation. The average improved residual predictive deviations (DRPD) were 0.06, 0.13, 0.19, and 0.13 for FD, log(1/R), MSC, and SNV, respectively. Thus, we concluded that spectral pretreatment improves the sample selection strategy, and the degree of its influence varies with the size of the calibration set and the type of pretreatment.},
author = {Liu, Yi and Liu, Yaolin and Chen, Yiyun and Zhang, Yang and Shi, Tiezhu and Wang, Junjie and Hong, Yongsheng and Fei, Teng and Zhang, Yang},
doi = {10.3390/rs11040450},
file = {:home/u0106869/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu et al. - 2019 - The influence of spectral pretreatment on the selection of representative calibration samples for soil organic matte.pdf:pdf},
issn = {20724292},
journal = {Remote Sensing},
keywords = {Multivariate regression,Sample selection,Spectral pretreatment,Visible and near-infrared reflectance,sample selection,sample selection manuscript},
mendeley-tags = {sample selection,sample selection manuscript},
number = {4},
title = {{The influence of spectral pretreatment on the selection of representative calibration samples for soil organic matter estimation using vis-NIR reflectance spectroscopy}},
volume = {11},
year = {2019}
}
@article{Puchwein1988,
abstract = {Near-Infrared (near-IR) spectra of samples are measured at 19 fixed wavelengths. After a factor analysis of absorbances the factor scores of samples can be used to delimit a region of factor space. The extension of this region and the distance of data points from each other are used as criteria to Iteratively remove samples as redundant. The samples left over are representative of the complete original set and are used for calibration by linear regression modeling. The potential of the selection algorithm to obtain calibrations for protein, moisture, and oil was tested with corn and rapeseed samples. The effort for laboratory analyses can be substantially reduced with no appreciable loss of prediction accuracy. The same principles also allow one to decide If a new sample will be covered by the calibration. {\textcopyright} 1988, American Chemical Society. All rights reserved.},
author = {Puchwein, Gerd},
doi = {10.1021/ac00157a015},
file = {:home/u0106869/vfonsecad/kul{\_}phd/literature/1998{\_}puchwein.pdf:pdf},
issn = {15206882},
journal = {Analytical Chemistry},
keywords = {sample selection manuscript},
mendeley-tags = {sample selection manuscript},
number = {6},
pages = {569--573},
title = {{Selection of Calibration Samples for Near-Infrared Spectrometry by Factor Analysis of Spectra}},
volume = {60},
year = {1988}
}
@book{Vapnik2000,
abstract = {The aim of this book is to discuss the fundamental ideas which lie behind the statistical theory of learning and generalization. It considers learning as a general problem of function estimation based on empirical data. Omitting proofs and technical details, the author concentrates on discussing the main results of learning theory and their connections to fundamental problems in statistics. These include: * the setting of learning problems based on the model of minimizing the risk functional from empirical data * a comprehensive analysis of the empirical risk minimization principle including necessary and sufficient conditions for its consistency * non-asymptotic bounds for the risk achieved using the empirical risk minimization principle * principles for controlling the generalization ability of learning machines using small sample sizes based on these bounds * the Support Vector methods that control the generalization ability when estimating function using small sample size. The second edition of the book contains three new chapters devoted to further development of the learning theory and SVM techniques. These include: * the theory of direct method of learning based on solving multidimensional integral equations for density, conditional probability, and conditional density estimation * a new inductive principle of learning. Written in a readable and concise style, the book is intended for statisticians, mathematicians, physicists, and computer scientists. Vladimir N. Vapnik is Technology Leader AT{\&}T Labs-Research and Professor of London University. He is one of the founders of statistical learning theory, and the author of seven books published in English, Russian, German, and Chinese.},
author = {Vapnik, Vladimir N.},
file = {:home/u0106869/vfonsecad/kul{\_}phd/literature/Books/(Statistics for Engineering and Information Science) Vladimir N. Vapnik-The Nature of Statistical Learning Theory-Springer (2000).pdf:pdf},
isbn = {0387987800},
issn = {1045-9227},
keywords = {sample selection manuscript},
mendeley-tags = {sample selection manuscript},
pmid = {18255760},
publisher = {Springer},
title = {{The nature of statistical learning theory}},
year = {2000}
}
@article{Stone1990,
abstract = {The paper addresses the evergreen problem of construction of regressors for use in least squares multiple regression. In the context of a general sequential procedure for doing this, it is shown that, with a particular objective criterion for the construction, the procedures of ordinary least squares and principal components regression occupy the opposite ends of a continuous spectrum, with partial least squares lying in between. There are two adjustable 'parameters' controlling the procedure: 'alpha', in the continuum [0, 1], and 'omega', the number of regressors finally accepted. These control parameters are chosen by cross- validation. The method is illustrated by a range of examples of its application},
author = {Stone, M and Brooks, R.J},
file = {:home/u0106869/vfonsecad/kul{\_}phd/literature/1990{\_}stone{\_}cont{\_}regression.pdf:pdf},
journal = {Journal of the Royal Statistical Society},
keywords = {sample selection manuscript},
mendeley-tags = {sample selection manuscript},
number = {2},
pages = {237--269},
title = {{Continuum Regression : Cross-Validated Sequentially Constructed Prediction Embracing Ordinary Least Squares , Partial Least Squares and Principal Components Regression Author ( s ): M . Stone and R . J . Brooks Published by : Blackwell Publishing for the}},
volume = {52},
year = {1990}
}
@book{Horn1985,
abstract = {Linear algebra and matrix theory have long been fundamental tools in mathematical disciplines as well as fertile fields for research. In this book the authors present classical and recent results of matrix analysis that have proved to be important to applied mathematics. Facts about matrices, beyond those found in an elementary linear algebra course, are needed to understand virtually any area of mathematical science, but the necessary material has appeared only sporadically in the literature and in university curricula. As interest in applied mathematics has grown, the need for a text and reference offering a broad selection of topics in matrix theory has become apparent, and this book meets that need. This volume reflects two concurrent views of matrix analysis. First, it encompasses topics in linear algebra that have arisen out of the needs of mathematical analysis. Second, it is an approach to real and complex linear algebraic problems that does not hesitate to use notions from analysis. Review and miscellanea -- Eigenvalues, eigenvectors, and similarity.},
author = {Horn, Roger A. and Johnson, Charles R.},
booktitle = {Matrix Analysis},
doi = {10.1017/cbo9780511810817},
file = {:home/u0106869/vfonsecad/kul{\_}phd/literature/Books/Roger A. Horn, Charles R. Johnson - Matrix Analysis (2013, Cambridge University Press) - libgen.lc.pdf:pdf},
isbn = {9780521548236},
keywords = {sample selection manuscript},
mendeley-tags = {sample selection manuscript},
title = {{Matrix Analysis}},
year = {1985}
}
@article{Tomic2013,
abstract = {Many statistical methods exist for evaluation of different aspects of assessor and panel performance. In order to gain a realistic and exhaustive overview over each individual's performance in different areas a large number of statistical results or plots need to be considered. Such a process often can be time consuming, cumbersome and may lead to biased conclusions. The proposed performance indices framework aims to act as an effective and practical complementary screening tool for panel leaders to help them quickly detect off-performances by assessors. The framework provides performance indices in the three following areas: agreement, repeatability and discrimination. Performance indices for agreement and repeatability are based on computations of either RV or RV2 coefficients, while the discrimination index is based on results from one- and two-way ANOVA. The performance indices can be easily presented in tables or graphs. Results show that they effectively detect underperforming assessors, and in combination with influence plots, provide a useful first overall impression in a rapid manner. Detailed performance issues can then be studied further in more detail with established statistical methods for performance evaluation. {\textcopyright} 2012 Elsevier Ltd.},
author = {Tomic, Oliver and Forde, Ciaran and Delahunty, Conor and N{\ae}s, Tormod},
doi = {10.1016/j.foodqual.2012.06.012},
file = {:home/u0106869/vfonsecad/kul{\_}phd/literature/2013{\_}oliver{\_}Performance Indices.pdf:pdf},
issn = {09503293},
journal = {Food Quality and Preference},
keywords = {Assessor and panel performance,Descriptive sensory analysis,Performance indices framework,RV and RV2 correlation coefficient,Screening tool,sample selection manuscript},
mendeley-tags = {sample selection manuscript},
number = {1},
pages = {122--133},
publisher = {Elsevier Ltd},
title = {{Performance indices in descriptive sensory analysis - A complimentary screening tool for assessor and panel performance}},
url = {http://dx.doi.org/10.1016/j.foodqual.2012.06.012},
volume = {28},
year = {2013}
}
@article{Artemiou2013,
abstract = {In this paper we demonstrate that a higher-ranking principal component of the predictor tends to have a stronger correlation with the response in single index models and sufficient dimension reduction. This tendency holds even though the orientation of the predictor is not designed in any way to be related to the response. This provides a probabilistic explanation of why it is often beneficial to perform regression on principal components-a practice commonly known as principal component regression but whose validity has long been debated. This result is a generalization of earlier results by Li (2007) [19], Artemiou and Li (2009) [2], and Ni (2011) [24], where the same phenomenon was conjectured and rigorously demonstrated for linear regression. {\textcopyright} 2013 Elsevier Inc.},
author = {Artemiou, Andreas and Li, Bing},
doi = {10.1016/j.jmva.2013.04.015},
file = {:home/u0106869/vfonsecad/kul{\_}phd/literature/Artemiou{\_}Li{\_}2013{\_}JMVA.pdf:pdf},
issn = {0047259X},
journal = {Journal of Multivariate Analysis},
keywords = {Permutation invariance,Principal component analysis,Rotation invariance,Single-index model,Sufficient dimension reduction,sample selection manuscript},
mendeley-tags = {sample selection manuscript},
pages = {176--184},
title = {{Predictive power of principal components for single-index model and sufficient dimension reduction}},
volume = {119},
year = {2013}
}
@article{DeJong1993,
abstract = {De Jong, S., 1993. SIMPLS: an alternative approach to partial least squares regression. Chemometrics and Intelligent Laboratory Systems, 18: 251-263. A novel algorithm for partial least squares (PLS) regression, SIMPLS, is proposed which calculates the PLS factors directly as linear combinations of the original variables. The PLS factors are determined such as to maximize a covariance criterion, while obeying certain orthogonality and normalization restrictions. This approach follows that of other traditional multivariate methods. The construction of deflated data matrices as in the nonlinear iterative partial least squares (NIPALS)-PLS algorithm is avoided. For univariate y SIMPLS is equivalent to PLS1 and closely related to existing bidiagonalization algorithms. This follows from an analysis of PLS1 regression in terms of Krylov sequences. For multivariate Y there is a slight difference between the SIMPLS approach and NIPALS-PLS2. In practice the SIMPLS algorithm appears to be fast and easy to interpret as it does not involve a breakdown of the data sets. {\textcopyright} 1993.},
author = {de Jong, Sijmen},
doi = {10.1016/0169-7439(93)85002-X},
file = {:home/u0106869/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/de Jong - 1993 - SIMPLS An alternative approach to partial least squares regression.pdf:pdf},
isbn = {0169-7439},
issn = {01697439},
journal = {Chemometrics and Intelligent Laboratory Systems},
keywords = {sample selection manuscript,simpls},
mendeley-groups = {PhD},
mendeley-tags = {simpls,sample selection manuscript},
number = {3},
pages = {251--263},
title = {{SIMPLS: An alternative approach to partial least squares regression}},
volume = {18},
year = {1993}
}
@misc{Wheeler2019,
author = {Wheeler, R.E},
keywords = {sample selection manuscript},
mendeley-tags = {sample selection manuscript},
title = {{optFederov.AlgDesign. The R project for statistical computing}},
url = {https://cran.r-project.org/web/packages/AlgDesign/AlgDesign.pdf},
year = {2019}
}
@article{Lam2015,
abstract = {Dynamic, interpreted languages, like Python, are attractive for domain-experts and scientists experimenting with new ideas. However, the performance of the interpreter is of-ten a barrier when scaling to larger data sets. This paper presents a just-in-time compiler for Python that focuses in scientific and array-oriented computing. Starting with the simple syntax of Python, Numba compiles a subset of the language into efficient machine code that is comparable in performance to a traditional compiled language. In addi-tion, we share our experience in building a JIT compiler using LLVM[1].},
author = {Lam, Siu Kwan and Pitrou, Antoine and Seibert, Stanley},
file = {:home/u0106869/vfonsecad/kul{\_}phd/literature/numba.pdf:pdf},
isbn = {9781450340052},
journal = {Proceedings of the Second Workshop on the LLVM Compiler Infrastructure in HPC - LLVM '15},
keywords = {2,a jit for numeric,com-,compiler,jit,just-in-time,llvm,numba is a function-at-a-time,python,sample selection manuscript},
mendeley-tags = {sample selection manuscript},
pages = {1--6},
title = {{Numba: a LLVM-based Python JIT compiler}},
url = {http://dl.acm.org/citation.cfm?doid=2833157.2833162},
year = {2015}
}
@article{Ferre1996,
abstract = {This paper discusses a methodology for selecting the minimum number of calibration samples in principal component regression (PCR) analysis. The method uses only the instrumental responses of a large set of samples to select the optimal subset, which is then submitted to chemical analysis and calibration. The subset is selected to provide a low variance of the regression coefficients. The methodology has been applied to UV- visible spectroscopy data to determine Ca2+ in water and near-IR spectroscopy data to determine moisture in com. In both cases, the regression models developed with a reduced number of samples provided accurate results. As far as precision is concerned, a similar root-mean-squared error of cross-validation (RMSECV) is found when comparing the new methodology with the results of the regression models that use the complete set of calibration samples and PCR. The number of analyzed samples in the calibration set can be reduced by up to 50{\%}, which represents a considerable reduction in costs.},
author = {Ferr{\'{e}}, Joan and {Xavier Rius}, F.},
doi = {10.1021/ac950482a},
file = {:home/u0106869/vfonsecad/kul{\_}phd/literature/1996{\_}ferre{\_}sample{\_}sel{\_}pcr:},
issn = {00032700},
journal = {Analytical Chemistry},
keywords = {sample selection manuscript},
mendeley-tags = {sample selection manuscript},
number = {9},
pages = {1565--1571},
title = {{Selection of the best calibration sample subset for multivariate regression}},
volume = {68},
year = {1996}
}
@article{Vapnik1994,
abstract = {A method for measuring the capacity of learning machines is described. The method is based on fitting a theoretically derived function to empirical measurements of the maximal difference between the error rates on two separate data sets of varying sizes. Experimental measurements of the capacity of various types of linear classifiers are presented.},
author = {Vapnik, Vladimir and Levin, Esther and Cun, Yann Le},
doi = {10.1162/neco.1994.6.5.851},
file = {:home/u0106869/vfonsecad/kul{\_}phd/literature/1994{\_}Vapnik{\_}Measuring{\_}the{\_}VC{\_}dimension{\_}of{\_}a{\_}learning.pdf:pdf},
issn = {0899-7667},
journal = {Neural Computation},
keywords = {model complexity,sample selection manuscript},
mendeley-tags = {model complexity,sample selection manuscript},
number = {5},
pages = {851--876},
title = {{Measuring the VC-Dimension of a Learning Machine}},
volume = {6},
year = {1994}
}
@article{Li2020,
abstract = {Active learning is a major area of interest within the field of machine learning, especially when the labeled instances are very difficult, time-consuming or expensive to obtain. In this paper, we review various active learning methods for manifold data, where the intrinsic manifold structure of data is also incorporated into the active learning query strategies. In addition, we present a new manifold-based active learning algorithm for Gaussian process classification. This new method uses a data-dependent kernel derived from a semi-supervised model that considers both labeled and unlabeled data. The method performs a regularization on the smoothness of the fitted function with respect to both the ambient space and the manifold where the data lie. The regularization parameter is treated as an additional kernel (covariance) parameter and estimated from the data, permitting adaptation of the kernel to the given dataset manifold geometry. Comparisons with other AL methods for manifold data show faster learning performance in our empirical experiments. MATLAB code that reproduces all examples is provided as supplementary materials.},
author = {Li, Hang and {Del Castillo}, Enrique and Runger, George},
doi = {10.1007/s11749-019-00694-y},
file = {:home/u0106869/vfonsecad/kul{\_}phd/literature/Li2020{\_}Article{\_}OnActiveLearningMethodsForMani.pdf:pdf},
issn = {18638260},
journal = {Test},
keywords = {Active learning,Classification,Gaussian process,Optimal design,sample selection manuscript},
mendeley-tags = {sample selection manuscript},
number = {1},
pages = {1--33},
publisher = {Springer Berlin Heidelberg},
title = {{On active learning methods for manifold data}},
url = {https://doi.org/10.1007/s11749-019-00694-y},
volume = {29},
year = {2020}
}
@article{Hubert2005,
abstract = {We introduce a new method for robust principal component analysis (PCA). Classical PCA is based on the empirical covariance matrix of the data and hence is highly sensitive to outlying observations. Two robust approaches have been developed to date. The first approach is based on the eigenvectors of a robust scatter matrix such as the minimum covariance determinant or an S-estimator and is limited to relatively low-dimensional data. The second approach is based on projection pursuit and can handle high-dimensional data. Here we propose the ROBPCA approach, which combines projection pursuit ideas with robust scatter matrix estimation. ROBPCA yields more accurate estimates at noncontaminated datasets and more robust estimates at contaminated data. ROBPCA can be computed rapidly, and is able to detect exact-fit situations. As a by-product, ROBPCA produces a diagnostic plot that displays and classifies the outliers. We apply the algorithm to several datasets from chemometrics and engineering. We introduce a new method for robust principal component analysis (PCA). Classical PCA is based on the empirical covariance matrix of the data and hence is highly sensitive to outlying observations. Two robust approaches have been developed to date. The first approach is based on the eigenvectors of a robust scatter matrix such as the minimum covariance determinant or an S-estimator and is limited to relatively low-dimensional data. The second approach is based on projection pursuit and can handle high-dimensional data. Here we propose the ROBPCA approach, which combines projection pursuit ideas with robust scatter matrix estimation. ROBPCA yields more accurate estimates at noncontaminated datasets and more robust estimates at contaminated data. ROBPCA can be computed rapidly, and is able to detect exact-fit situations. As a by-product, ROBPCA produces a diagnostic plot that displays and classifies the outliers. We apply the algorithm to several datasets from chemometrics and engineering.},
author = {Hubert, Mia and Rousseeuw, Peter J. and {Vanden Branden}, Karlien},
doi = {10.1198/004017004000000563},
file = {:home/u0106869/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hubert, Rousseeuw, Vanden Branden - 2005 - ROBPCA A new approach to robust principal component analysis.pdf:pdf},
isbn = {0040170040000},
issn = {00401706},
journal = {Technometrics},
keywords = {High-dimensional data,Principal component analysis,Projection pursuit,Robust methods,sample selection manuscript},
mendeley-groups = {PhD/nir2019},
mendeley-tags = {sample selection manuscript},
number = {1},
pages = {64--79},
pmid = {3548},
title = {{ROBPCA: A new approach to robust principal component analysis}},
volume = {47},
year = {2005}
}
